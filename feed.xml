<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="4.2.1">Jekyll</generator><link href="https://otch80.github.io/feed.xml" rel="self" type="application/atom+xml" /><link href="https://otch80.github.io/" rel="alternate" type="text/html" /><updated>2022-02-09T20:23:20+09:00</updated><id>https://otch80.github.io/feed.xml</id><title type="html">상황정리</title><subtitle>추천시스템을 공부하는 중입니다</subtitle><author><name>조민규</name></author><entry><title type="html">RecSys Challenge 2015: ensemble learning with categorical features 리뷰</title><link href="https://otch80.github.io/recommend%20system/Recsys-challenge-2015/" rel="alternate" type="text/html" title="RecSys Challenge 2015: ensemble learning with categorical features 리뷰" /><published>2022-01-23T00:00:00+09:00</published><updated>2022-01-23T00:00:00+09:00</updated><id>https://otch80.github.io/recommend%20system/Recsys%20challenge%202015</id><content type="html" xml:base="https://otch80.github.io/recommend%20system/Recsys-challenge-2015/"><![CDATA[<p><br /></p>

<p>Yandex Data Factory 소속인 Peter Romov, Evgeny Sokolov가 작성한 대회논문 RecSys Challenge 2015: ensemble learning with categorical features를 기반으로 Recsys Challenge 2015를 공부해보려 합니다.</p>

<p>해당 팀은 최종 score 63,102 으로 전체 1위에 랭크하였으며, 2위 와는 약 2,000 점의 점수 차이를 나타내었습니다.</p>

<p>우선 2015년에 개최된 recsys challenge에 대해 개인적으로 분석한 내용을 간략하게 설명을 해보겠습니다.</p>

<p>대회는 YOOCHOOSE에서 제공한 유럽 E-commerce 의 로그로 사용자의 클릭과 구매 정보를 가지고 있습니다. <br />
두 데이터를 통해 클릭 로그에서 사용자의 아이템 구매 여부를 예측하는 알고리즘을 개발하여, 학습에 사용되지 않은 새로운 사용자의 아이템 구매를 예측하는 것입니다.
<br /><br /></p>

<p><img src="https://user-images.githubusercontent.com/48629275/150664086-cf68ea1a-4a57-4ec8-a073-326bafc8d316.JPG" alt="대회 설명" /></p>

<p>우선 A 그룹 사용자의 click log를 분석해 모델을 학습 시킵니다. <br />
이후 학습된 모델을 통해 B 그룹의 클릭 로그를 통해 아이템 구매를 예측 하는 방식을 간략하게 그려보았습니다.
<br /><br /></p>

<p><img src="https://user-images.githubusercontent.com/48629275/150664088-ec26c208-cc6d-466a-bc52-d42152642023.JPG" alt="데이터셋" /></p>

<p>대회에서 제공하는 데이터는 다음과 같습니다.</p>

<p>yoochoose-buys.dat - 사용자가 물건을 구입할 때 발생하는 로그입니다. <br />
yoochoose-clicks.dat - 사용자가 물건을 클릭할 때 발생하는 로그입니다. <br />
yoochoose-test.dat - 예측해야 하는 클릭 로그입니다.</p>

<p>buy와 click 파일을 통해 모델을 train 시키고, buy 로그를 활용해 정답을 확인하는 방식으로 모델을 학습시킵니다.
<br /><br /></p>

<p><img src="https://user-images.githubusercontent.com/48629275/150664089-7190bf8a-c16e-4365-b679-8cac6bfd8bd5.JPG" alt="데이터 특징" /></p>

<p>데이터의 특징을 정리해보았습니다.</p>
<ol>
  <li>제공된 데이터는 <strong>2014년의 4월 1일부터 9월 30일</strong> 까지 약 180일 기간의 데이터를 가지고 있습니다.</li>
  <li>제공된 <strong>session ID</strong> 는 <strong>User ID</strong> 가 아닙니다.
    <ul>
      <li>특정 사용자의 행동 특성을 고려한 collaborative-filtering 기법은 적절하지 않다는 점을 알 수 있습니다.</li>
    </ul>
  </li>
  <li>클릭 파일에 기록된 세션의 수는 약 9백만명, 구매 파일에 기록된 세션의 수는 약 50만명으로, 정확한 수치는 아니지만 단순 수치상으로 봤을때 <strong>클릭 대비 아이템 구매의 비율은 5%</strong> 정도로 구성되어 있다는 사실을 알 수 있습니다.</li>
  <li>물품의 가격은 일정하지 않고, <strong>시간의 변화에 따라 지속적으로 변동</strong>됩니다.</li>
  <li>물품의 카테고리는 한번에 하나씩 기록되지만, <strong>다양한 카테고리</strong>를 가질 수 있습니다.
    <ul>
      <li>예를들어 <strong>운동화</strong> 라고 했을 때, 운동 용품으로 접근한 사용자에겐 <strong>운동</strong> 카테고리가, 패션 용품으로 접근한 사용자에겐 <strong>의류</strong> 카테고리가 붙을 수 있다는 점입니다.</li>
      <li>카테고리는 크게 3가지로 나뉩니다.
        <ol>
          <li>프로모션으로 판매가 진행된 상품 혹은 고객의 특별 주문 상품</li>
          <li>missing value</li>
          <li>해당 아이템의 카테고리</li>
        </ol>
      </li>
    </ul>
  </li>
</ol>

<p><br /><br /></p>

<p><img src="https://user-images.githubusercontent.com/48629275/150664091-9ba40b0a-99be-4631-83aa-929c834292ef.JPG" alt="세션과 유저의 차이" /></p>

<p>왜 session ID와 user ID를 동일하게 고려하지 않는지에 대하여 간단하게 정리해보았습니다.</p>

<p>User란 일반적으로 우리가 생각하는 사용자 입니다. 그렇기 떄문에 다른 사용자들과 구별되는 식별성을 가지고 있습니다. User는 Unique ID 혹은 Client ID 라고 불립니다. 해당 서비스를 사용하는 사용자의 ID는 언제나 1개일 수 밖에 없습니다.</p>

<p>그에 반해 Session은 일정시간 사용자의 반응이 없으면 새로 발급되는 특징을 가지고 있습니다. 사용자가 일정 시간 이후에 사이트에 재접속 할 경우 새로운 세션이 생성됩니다. 그렇기 때문에 한 사용자는 여러 세션을 가질 수 있기 때문에 유일한 식별자로 분류할 수 없습니다.</p>

<p>간략한 내용 설명은 마무리 했으니 논문 내용을 다루어 보겠습니다 <br />
<br /><br /></p>

<p><img src="https://user-images.githubusercontent.com/48629275/150665513-5a9cb6ad-b40e-4d3c-8d8f-01332bac6970.JPG" alt="대회 점수 측정방식 1" /></p>

<p>다음은 논문에서 설명한 대회의 점수 측정 방식입니다.</p>

<p>수식의 흐름대로 설명을 해보겠습니다.</p>

<p>$Q(h,S_test)$ 는 참가자가 제출한 결과와 실제 정답을 비교하였을 때의 결과값입니다.</p>

<p>이때 특이한 조건이 붙는데, 제출한 결과 중 <strong>세션 s가 물건을 구매할 것으로 판단되는 사용자</strong>에 대해서만 계산을 수행합니다.</p>

<p>예측 결과가 positive한 부분애 대헤서만 점수를 측정하는 방식인데, 이는 모델이 세션 s가 물건을 구매하지 않는다고 판단을 한 경우 (Negative) 에 대해서는 (TN,FN) 고려하지 않는 다는 점입니다.</p>

<p>왜 이런 점수 측정 방식을 채택했을 지 고민을 해보았습니다.</p>

<p>대회를 개최하는 시기의 추천은 <strong>양질의 추천</strong>을 하는 것 보다는, <strong>사용자에게 많은 아이템을 추천해주고 그 중에서 건지기만 하면 된다</strong> 라는 방식의 접근이 우선시 되었던 것으로 추측하고 있습니다.</p>

<p>개인적으로 무분별한 정보의 제공은 서비스 만족도를 저하시킬 수 있다고 생각하기 때문에 서비스 방향성의 변화를 알 수 있는 재밌는 점이라 생각이 됩니다.</p>

<p>다시 수식으로 돌아와서, 제출한 데이터 중 1개 이상의 아이템을 구매할 것으로 생각되는 사용자에 대해서만 각 세션별 점수를 측정합니다.</p>

<p>$S^b_{test}$ 는 정답지의 아이템을 구매한 세션 집합, $S_test$ 는 정답지의 모든 세션 집합을 나타냅니다.</p>

<p>즉 $ S^b_{test} \over S_{tset} $는 정답 데이터 중에서 <strong>전체 세션 중 구매 세션의 비율을 나타내는 상수값</strong>임을 알 수 있습니다.</p>

<p>$ isEmpty(y(s)) $ 는 구매를 할 것으로 예측한 세션이, 실제로 아이템을 구매한 내역이 존재하면 0 으로 변환하여 구매 비율을 추가 점수로 제공합니다. 하지만 실제 구매 내역이 없는 경우 1 로 변환하여 구매 비율 점수를 패널티로 부여합니다.</p>

<p>$ J(y(s), h(s)) $ 는 세션 s가 실제 구매한 내역과 제출한 세션 s의 구매 내역을 비교하여 jaccard 유사도를 통해 유사한 정도를 수치화 시킵니다. <br />
<br /><br /></p>

<p><img src="https://user-images.githubusercontent.com/48629275/150665514-267c4ae9-8173-49c3-bd8d-70e455f31ee1.JPG" alt="대회 점수 측정방식 2" /></p>

<p>수식의 앞을 자세히 살펴보면 우선 positive 라고 예측한 (세션 s가 아이템을 구매할 것으로 예측한) 내용에 대해서 시그마를 적용하면, 해당 내용이 정답인지 오답인지 $ isEmpty(y(s)) $ 에 의해 구분이 될 것입니다.</p>

<p>이를 FP, TP로 표기하였을 때 다음과 같은 내용으로 단순하게 표현할 수 있습니다.
<br /><br /></p>

<p><img src="https://user-images.githubusercontent.com/48629275/150664095-d6c8e8f4-c832-4c79-bc36-360dc45479fc.JPG" alt="대회 점수 측정방식 3" /></p>

<p>결국 대회에서 측정하는 값은 다음과 같습니다.</p>

<ol>
  <li>purchase score : 세션의 구매 여부를 예측한 점수</li>
  <li>jaccard score : 세션 s의 구매 아이템 리스트를 예측한 점수
<br /><br /></li>
</ol>

<p><img src="https://user-images.githubusercontent.com/48629275/150664097-96f989fc-ea04-411b-8317-dcc6a04f01f5.JPG" alt="Outline" /></p>

<p>해당 정보를 통해 저자들은 다음과 같은 아이디어를 제시하였습니다.</p>

<ol>
  <li>이 세션이 물건을 살 의향이 있는지 예측하는 모델 제작</li>
  <li>만약 물건을 살 의향이 있는 세션이라면, 어떤 물건을 살 것인지 예측하는 모델 제작</li>
</ol>

<p>각 정보에 해당하는 모델을 각기 수행시키는 것으로 방향성을 설정하였습니다.
<br /><br /></p>

<p><img src="https://user-images.githubusercontent.com/48629275/151382411-0fa433c7-1a0d-42ae-9eea-70be04270b03.JPG" alt="예측방식" /></p>

<ul>
  <li>모델의 출력 결과는 확률값으로 출력합니다.</li>
</ul>

<ol>
  <li>해당 세션이 물건을 살 확률은 얼마나 되는가?</li>
  <li>물건을 살 확률이 $ \alpha_{p} $ 보다 작으면 0 반환, $ \alpha_{p} $ 이상이면 세션 정보를 다음 모델로 넘겨준다</li>
  <li>해당 세션이 클릭한 물건을 살 확률은 얼마나 되는가?</li>
  <li>클릭한 물건을 살 확률이 $ \alpha_{i} $ 보다 크면 결과값 1, 아니면 0 반환</li>
</ol>

<p>그렇기 때문에 논문의 저자들은 결과를 구분하기 위한 $ \alpha_{p}, \alpha_{i} $ 인 $threshold$ 를 구하는 과정이 중요하다고 설명하고 있습니다.
<br /><br /></p>

<p><img src="https://user-images.githubusercontent.com/48629275/150664099-f080a4b7-e127-48f4-9002-8852c1e00576.JPG" alt="point" /></p>

<p>데이터 분석에 앞서 분석 방향에 대한 간략한 정보를 언급하였습니다.</p>

<ul>
  <li>Train / Test 데이터셋 모두 동일한 시간대를 가지기 때문에 time feature 를 활용할 수 있다</li>
</ul>

<p>일반적으로 결과를 예측하는 방식은 과거의 데이터에서 모델이 feature를 학습하고, 미래의 데이터에 대해 예측하는 방식입니다.</p>

<p>하지만 이번 데이터셋의 경우는 train 과 test 모두 동일한 시간의 범위를 가지고 있기 때문에, 특정 시간에 발생한 이벤트를 동일하게 적용할 수 있는 상황입니다.</p>

<p>예를 들어 8월에 있었던 여름 제품 세일과 같은 특정 시간만의 이벤트를 예측에도 동일하게 적용할 수 있다는 얘기가 됩니다.</p>

<p>해당 접근 방식은 좋은 방식으로 생각이 되지만, 이런 데이터셋을 제공한 대회가 어떤 결과를 얻고 싶어서 이런 특성을 가진 데이터를 제공하였는지는 의문이 듭니다.</p>

<p>추가로 저자들은 제품의 가격과, 구매 수량은 학습에 사용하지 않았다고 합니다.</p>

<p>상품을 구매함에 있어서 제품의 가격은 분명 주요한 요인이 될 것인데 이러한 부분을 배제한 이유도 궁금하지만 성능에서 이미 증명을 하였기 떄문에 크게 생각하지는 않기로 하였습니다. <br />
<br /><br /></p>

<p><img src="https://user-images.githubusercontent.com/48629275/150664100-34db226e-6bc2-46fa-9163-02696d3a22f4.JPG" alt="EDA 1" /></p>

<p>데이터를 살펴보면 시간에 따른 구매율이 존재하는 것을 확인할 수 있습니다.</p>

<p>그리고 상대적으로 심야시간 보다는 사람들이 많이 활동하는 시간에 구매율도 높은 모습을 볼 수 있었습니다.</p>

<p>동시에 근무를 하는 주중의 구매율 보다 주말에 사람들의 쇼핑 활동이 많은 것을 알 수 있었습니다.</p>

<p>이때 중요한 부분은 특가 프로모션이나 공휴일과 같은 단순 데이터에서는 나타나지 않는 시간적 특성이 추가로 존재하기 때문에 시간 feature가 곧 정답은 아님을 파악해야 합니다. <br />
<br /><br /></p>

<p><img src="https://user-images.githubusercontent.com/48629275/150664101-96de65ba-6dfb-4448-9192-0e22a49fa5d2.JPG" alt="EDA 2" /></p>

<p>클릭의 관점에서 접근한 분석 내용입니다.</p>

<p>당연히 세션의 누적 클릭 수가 높을수록, 해당 세션은 아이템 구매 의사가 있는 것으로 파악을 할 수 있습니다.</p>

<p>살 물건이 없어서 가볍게 둘러보는 사람에 비해, 물건을 비교하고 어떤 물건을 살 지 고민하는 사람의 클릭수가 많을 수 밖에 없다는 점이 데이터에 나타나고 있습니다.</p>

<p>하지만 클릭수가 많을 수록 반드시 구매율이 높은것은 아님을 보여주기 위해 인기항목에 대한 분석도 수행하였습니다.</p>

<p>전체 학습 데이터에서 클릭 수가 많은 상위 아이템의 구매율을 살펴보았을 때, 각 항목별로 구매율에 차이가 크게 나타남을 알 수 있습니다.</p>

<p>이러한 데이터를 바탕으로 클릭 수가 많을수록 구매율이 항상 높은 것은 아님을 알 수 있습니다. <br />
<br /><br /></p>

<p><img src="https://user-images.githubusercontent.com/48629275/151382519-25f93df0-3651-4abb-8674-53c86f804954.JPG" alt="feature extract" /></p>

<p>모델 학습을 위해 추출한 feature 입니다.</p>

<p>우선 purchase score를 높이기 위한 세션의 아이템 구매 의사 예측을 하기위한 feature와,</p>

<p>jaccard score를 높이기 위한 세션의 구매 아이템 예측을 위한 feature로 구분하였습니다.</p>

<p>자세한 내용은 표를 참고해주시면 감사하겠습니다.</p>

<p>전체적으로 시간에 대한 분석을 위주로 분석을 수행하였다는 점을 알 수 있었습니다.</p>

<p>여기서 특이한 점을 알 수 있었는데, 시간 데이터를 굉장히 다양한 방법으로 분리를 시켰다는 점입니다.</p>

<p>개인적으로 아무리 많은 로그가 남는 사이트라고 하더라도 몇 시부터 몇 시까지 이벤트를 진행한다 정도만 알고 있어도 많은 도움이 될 것으로 생각을 했습니다.</p>

<p>그에 반해 저자들은 초단위 까지 나눠서 모델에 학습을 시켰는데, 이런 과정이 정말로 모델 예측이 필요한 데이터를 추출하는 과정인지에 대한 검증도 추가해주었으면 하는 생각이 들었습니다.</p>

<p>물론 제가 코드를 실행시키며 상관관계 분석을 할 수 있지만, 저자들이 사용한 칼럼의 수는 400개로 제 컴퓨팅 환경에서는 불가능한 상황이기 때문에 안타까운 마음이 들 뿐입니다. <br />
<br /><br /></p>

<p><img src="https://user-images.githubusercontent.com/48629275/150664103-6c88ad3e-fcd9-4dc1-9378-7e9cbb2a5e26.JPG" alt="사용 모델" /></p>

<p>방대한 데이터를 처리하기 위한 모델을 선별하는 과정을 수행하였다고 합니다.</p>

<p>2015년이면 그렇게 다양한 모델이 존재하지는 않았을 것으로 생각이 됩니다.</p>

<p>저자들은 모델 선별에 고려사항으로 다음과 같은 내용을 언급하였습니다.</p>

<ul>
  <li>여러 수준의 범주형 feature를 지원하는 ML</li>
</ul>

<p>XGBoost, Ensemble, GBM 등의 모델은 범주형 feature를 직접적으로 지원하지 않기 때문에 MatrixNet 모델을 활용하였다고 설명하였습니다.</p>

<p>MatrixNet 모델은 2009년에 개발된 Gradient Boosting 라이브러리로, 트리 기반의 모델입니다.</p>

<p>저자 Andrey Gulin가 발표한 2012년 Matrixnet Technical report에 따르면 해당 모델은</p>

<blockquote>
  <p>[Matrixnet Technical report 내용 중]</p>
  <ul>
    <li>MatrixNet is an implementation of gradient boosted decision trees algorithm</li>
    <li>MatrixNet is bit different from standard
      <ul>
        <li>Using Oblivious Trees</li>
        <li>Accounting for sample count in each leaf</li>
      </ul>
    </li>
  </ul>
</blockquote>

<p>라고 설명하고 있습니다.</p>

<p>하지만 저의 짧은 식견으로는 정확히 이해할 수 없었기 때문에 설명은 다음에 기회가 된다면 해보도록 하고, 다시 논문내용으로 복귀하겠습니다.</p>

<p>MatrixNet의 발표 ppt 는 해당 링크에서 확인할 수 있습니다. - http://www.slideshare.net/yandex/matrixnet. <br />
<br /><br /></p>

<p><img src="https://user-images.githubusercontent.com/48629275/150664104-aaffa673-578c-405e-9a00-833057987093.JPG" alt="결과 1" /></p>

<p>모델을 수행하고 threshold를 지정함에 있어서 다음과 같은 방식을 수행하였습니다.</p>

<p>우선 jaccard score가 최대가 되는 $ \alpha_{i} $를 설정합니다.</p>

<p>이후 $ \alpha_{p} $ 를 설정합니다. <br />
<br /><br /></p>

<p><img src="https://user-images.githubusercontent.com/48629275/150664106-0497b105-99b8-4331-a713-7e3692dadb69.JPG" alt="결과 2" /></p>

<p>최종적으로 모델 학습시간에는 12시간이 소요되었고, 초당 4000개의 로그를 예측할 수 있다고 설명하였습니다.</p>

<p>Validation set 에 대해서는 Precision (살 것이라고 예측한 세션 중 맞춘 비율) 16%, Recall (실제 구매 세션 중 검출 비율) 77%, AUC 0.85, jaccard measure 0.765 의 성능을 나타내었음을 설명하였습니다. <br />
<br /><br /></p>

<p>2015년에 진행된 대회는 Negative에 대한 예측을 score에 반영하지 않는 모습과 예측 데이터셋의 동일한 시간 분포를 통해 대회가 추구하는 서비스의 추천 방향에 대한 의문이 들었습니다.</p>

<p>아무래도 7년이 지난 지금에서야 살펴보는 내용이기 때문에 차이가 많이 나는 부분이 존재할 수 밖에 없다는 점을 알 수 있었고,</p>

<p>제가 지금 공부하는 내용도 나중에는 결국 당연하지 못한 내용으로 구분 지어질 수 있다는 점을 항상 생각하며, 보다 넓은 시야를 통해 스스로를 되돌아 보는 태도를 지녀야 할 것으로 생각이 들었습니다.</p>

<p>긴 글 읽어 주셔서 감사합니다. <br />
<br /></p>]]></content><author><name>조민규</name></author><category term="recommend system" /><category term="논문리뷰" /><category term="recsys challenge" /><summary type="html"><![CDATA[]]></summary></entry><entry><title type="html">AMNN을 활용한 맞춤형 여행지 추천 서비스</title><link href="https://otch80.github.io/recommend%20system/%EC%97%AC%ED%96%89%EC%A7%80%EC%B6%94%EC%B2%9C/" rel="alternate" type="text/html" title="AMNN을 활용한 맞춤형 여행지 추천 서비스" /><published>2022-01-12T00:00:00+09:00</published><updated>2022-01-12T00:00:00+09:00</updated><id>https://otch80.github.io/recommend%20system/%EC%97%AC%ED%96%89%EC%A7%80%EC%B6%94%EC%B2%9C</id><content type="html" xml:base="https://otch80.github.io/recommend%20system/%EC%97%AC%ED%96%89%EC%A7%80%EC%B6%94%EC%B2%9C/"><![CDATA[<p><br /></p>

<p>안녕하세요 이번에는 AMNN 모델을 활용해서 제작한 여행지 추천 서비스에 대한 전반적인 설명과 프로젝트 진행하며 다루었던 여러 이슈들에 대해 포스팅해보려 합니다.</p>

<p>관련 코드는 제 깃허브에서 확인하실 수 있습니다.</p>

<ul>
  <li><a href="https://github.com/otch80/AMNN"> https://github.com/otch80/AMNN </a></li>
</ul>

<p><br /></p>

<h1 id="서비스-주제">서비스 주제</h1>
<blockquote>
  <p>사용자 맞춤형 여행지 추천 서비스</p>
</blockquote>

<p><br /></p>

<h1 id="소개">소개</h1>
<blockquote>
  <p>초기 화면</p>
</blockquote>

<p><img src="https://user-images.githubusercontent.com/48629275/152745653-13504368-d741-4517-a4a1-f0a17b150c27.png" alt="서비스 화면" /></p>

<p>서비스 진입 시 볼 수 있는 화면입니다</p>

<p>“당신이 선택한 사진을 통해 성공적인 여행을 책임진다” 는 뜻의 Picture + Victory 를 합친 저희 프로젝트 팀명 PicTory를 보실 수 있습니다.</p>

<p><br /></p>

<blockquote>
  <p>서비스 설명</p>
</blockquote>

<p><img src="https://user-images.githubusercontent.com/48629275/152745651-ff26fba9-630d-4945-99eb-e2053bc1f834.png" alt="서비스 설명" /></p>

<p>페이지를 내리게 되면 저희 서비스를 소개하는 화면을 보실 수 있는데요,</p>

<p>사용자가 선택한 3장의 여행지 이미지만을 통해서 맞춤형 국내 관광지를 추천하는 서비스를 설명하고 있습니다.</p>

<p><br /></p>

<blockquote>
  <p>관광지 사진</p>
</blockquote>

<p><img src="https://user-images.githubusercontent.com/48629275/152745643-4c253f16-c317-410e-811f-359e09ac40dd.png" alt="관광지 사진" /></p>

<p>저희가 제공하는 관광지의 예시를 몇개 보실 수 있습니다.</p>

<p>위치와 관광지 관련 정보를 확인 할 수 있습니다.</p>

<p><br /></p>

<blockquote>
  <p>관광지 소개</p>
</blockquote>

<p><img src="https://user-images.githubusercontent.com/48629275/152745647-fd829901-6761-4e86-858c-9d66a2e46475.png" alt="관광지 소개" /></p>

<p>이미지나 텍스트를 클릭하게 되면 해당 카카오맵 API를 통해 해당 지역의 실제 위치를 확인할 수 있습니다.</p>

<p><br /></p>

<blockquote>
  <p>사용자 클릭</p>
</blockquote>

<p><img src="https://user-images.githubusercontent.com/48629275/152745649-535d0193-1fb4-4cf1-8556-cb208ce95d8d.png" alt="사용자 클릭" /></p>

<p>간단한 회원가입 후 로그인을 한 상태에서, 초기 화면의 ‘들어가기’ 버튼을 누르면 총 6장의 관광지 사진을 볼 수 있습니다.</p>

<p>사진 선택 과정을 총 3번 진행하게 되며, 상태바를 통해 진행상황을 확인할 수 있습니다.</p>

<p><br /></p>

<blockquote>
  <p>여행지 추천</p>
</blockquote>

<p><img src="https://user-images.githubusercontent.com/48629275/152745656-8d1cffe7-cfb6-4a54-b956-a72b0ec07d77.png" alt="여행지 추천" /></p>

<p>총 18장의 사진 중에서 3장을 선택하는 과정을 통해 사용자의 취향을 파악하여 좋아할 것으로 생각되는 여행지 3곳을 추천해줍니다.</p>

<p>추천 결과가 마음에 들었는지 평가할 수 있는 버튼도 준비해두었습니다.</p>

<p><br /></p>

<p>서비스를 구현하기 위해 사용한 기술을 설명하겠습니다.</p>

<p><br /></p>

<h1 id="추천-모델">추천 모델</h1>
<blockquote>
  <p>AMNN (Attention-Based Multimodal Neural Network Model for Hashtag Recommendation)</p>
</blockquote>

<p><br /></p>

<p>해당 모델은 2020년 IEEE에 publish된 논문 내용으로 Qi Yang, Gaosheng Wu, Yuhua Li, Ruixuan Li, Xiwu Gu, Huicai Deng, and Junzhuang Wu 등 7명의 저자가 작성하였습니다.</p>

<p>혹시나 논문의 자세한 내용이 궁금하실 분들을 위해 DOI 남겨두겠습니다.</p>

<ul>
  <li>link : <a href="https://doi.org/10.1109/TCSS.2020.2986778"> 10.1109/TCSS.2020.2986778 </a></li>
</ul>

<p><br /></p>

<h2 id="amnn-간단-설명">AMNN 간단 설명</h2>

<blockquote>
  <p>마이크로 블로그 게시글에 적합한 해시태그를 추천하는 모델</p>
</blockquote>

<p><br /></p>

<p>프로젝트에 사용한 AMNN 모델을 간단하게 설명하자면 이렇습니다.</p>

<p>sns 에 포스팅한 게시글의 사진과 텍스트를 분석해서 맞춤형 해시태그를 추천해주는 모델입니다.</p>

<p>해시태그로 어떻게 여행지를 추천했는지 설명하기에 앞서, 모델을 잠시 설명하고 가겠습니다.</p>

<p><br /></p>

<p>우선 AMNN의 정식 명칭은 Attention-Based Multimodal Neural Network Model 입니다.</p>

<p>여기서 핵심 키워드는 <strong>Attention</strong> 과 <strong>Multimodal</strong> 인데요,</p>

<p><br /></p>

<ul>
  <li>Attention</li>
</ul>

<p>Attention 은 쉽게 말해 모델의 성능을 높이기 위해 데이터에서 <strong>집중해야 하는 부분을 강조</strong>하는 방식입니다.</p>

<p>우리가 보통 인스타 피드에 해시태그를 달때 새해 일출사진을 올린다고 가정하면,</p>

<p>#일출, #새해다짐 같은 표현하고싶은 포인트를 말하지 #태양부터_바다까지_그라데이션 이런식으로 불필요한 정보는 넣지 않는다는 점과 동일합니다.</p>

<p><br /></p>

<ul>
  <li>Multimodal</li>
</ul>

<p>논문에서 말하는 Multimodal이란 쉽게 말해 <strong>여러가지 종류의 데이터를 조합해서 하나의 데이터를 생성</strong>하는 방식입니다.</p>

<p>단순 텍스트 예측을 위해서는 글만 있어도 충분하지만, 해시태그를 유추하기 위해서는 사용자가 표현하고 싶은 내용이 무엇인지 글과 사진을 함께 고려하는 것이 더 효과적일 것입니다.</p>

<p>이런 이유 때문에 이미지, 텍스트 등의 한가지 이상 데이터를 조합해서 사용하는 것입니다.</p>

<p><br /></p>

<p>다음은 논문에서 제시한 모델의 사진입니다.</p>

<p><br /></p>

<p><img src="https://user-images.githubusercontent.com/48629275/152754934-cc33153d-6381-41f2-b4cc-3b02a433aa62.png" alt="AMNN" /></p>

<p>모델에 대한 자세한 내용은 다음 게시글에서 다루기위해 지금은 짧게 설명하겠습니다.</p>

<ul>
  <li>이미지</li>
</ul>

<p>이미지를 입력받아 Convolutional Layer와 LSTM, Attention Layer 를 통과해 <strong>Image features</strong>를 생성합니다.</p>

<p>Convolutional Layer 는 resnet, vgg, inception 등 다양한 레이어가 있지만 이번 프로젝트에서는 <strong>이미지와 텍스트 둘 다 사용한 경우에서 가장 성능이 좋다</strong>고 설명한 <strong>resnet50</strong> 을 사용했습니다.</p>

<p><br /></p>

<ul>
  <li>텍스트</li>
</ul>

<p>게시글을 입력받아 토큰화를 수행한 뒤 LSTM, Attention Layer 를 통과시켜 text feature를 생성합니다.</p>

<p><br /></p>

<p>저자들은 이 두 과정을 Encoder 라고 설명하였습니다.</p>

<p>추출된 두 feature를 <strong>단순 병합</strong> 한 뒤에, 해당 게시글의 해시태그를 <strong>원-핫인코딩</strong> 시켜 <strong>임베딩 벡터</strong>로 변환합니다.</p>

<p>위 과정을 통해 모델에게 “이 게시글에는 이런 해시태그가 달린 다” 라는 것을 학습시킵니다.</p>

<p>저자들은 해당 과정을 Decoder 라고 설명하였습니다.</p>

<p><br /></p>

<h1 id="데이터셋">데이터셋</h1>

<p>이제 모델 동작 과정을 알았으니 어떤 데이터를 사용했는지 설명하겠습니다.</p>

<h2 id="학습-데이터">학습 데이터</h2>

<p>아무래도 해시태그라 하면 <strong>인스타</strong> 혹은 <strong>트위터</strong> 위주로 사용되는 단어로 저자들은 인스타에서 데이터를 수집하였습니다.</p>

<p>수집 데이터를 제공해주고 있지만 <strong>강아지</strong>, <strong>고양이</strong> 같이 여행지와 직접적인 관련이 없는 데이터기 때문에 모델이 제대로 학습을 못할것같다는 생각이 들었습니다.</p>

<p>이를 해결하기 위해 크롤러를 통해 광고를 최대한 제외시킨 약 1만개의 인스타 데이터를 수집하여 학습에 사용했습니다.</p>

<p><br /></p>

<h2 id="성능비교">성능비교</h2>

<p>자체 수집한 데이터로 학습한 모델과 논문의 모델 성능을 비교한 그래프입니다.</p>

<p><img src="https://user-images.githubusercontent.com/48629275/152928200-a331fad8-027b-44e3-94a6-81e19d80722a.png" alt="precision" />
<img src="https://user-images.githubusercontent.com/48629275/152928205-a9fe2dc5-905e-494b-a81d-8a0070b13c34.png" alt="recall" />
<img src="https://user-images.githubusercontent.com/48629275/152928207-c9911338-927b-4081-af64-c1317d2e1019.png" alt="accuracy" /></p>

<p>논문과 다른 학습 데이터를 사용한 점을 감안하여 살펴보겠습니다.</p>

<p>논문 모델은 Precision 과 Accuracy 가 조금 더 높은 경향을 보이고, 새로 학습한 모델은 Recall 이 더 높은 값을 나타내고 있습니다.</p>

<p>제가 학습시킨 모델이 실제 해시태그를 더 잘 맞췄지만, 다양하지 못한 해시태그 추천이 이루어진게 아닌가 생각이 들었습니다.</p>

<p><br /></p>

<h2 id="테스트-데이터">테스트 데이터</h2>

<p>비상업적 용도로 서비스를 개발한다고 해도 인스타의 실제 게시글을 서비스에 활용하기엔 법적인 문제가 발생할 위험이 있기 때문에 사용자에게 제공될 항목은 공공데이터를 사용했습니다.</p>

<p>한국관광공사 API를 통해 여행지 사진과 텍스트 약 1만건을 수집하였습니다.</p>

<p><img src="https://user-images.githubusercontent.com/48629275/152928902-4919f8cc-e117-4408-8109-3f0a4799e2b3.png" alt="관광공사API" /></p>

<p>보시는 것 처럼 대표이미지와 관련 텍스트를 제공하고 있기 때문에 모델 학습에 필요한 데이터를 모두 수집할 수 있습니다.</p>

<p><br /></p>

<h2 id="여행지-해시태그-추출-결과">여행지 해시태그 추출 결과</h2>

<p>모델이 어떤식으로 해시태그를 추출했는지 실제 예측 결과를 보겠습니다.</p>

<p><br /></p>

<p><img src="https://user-images.githubusercontent.com/48629275/152929553-8d3e7b28-85ae-4e3a-abaa-64c1b27d246b.png" alt="관광공사_광안리" /></p>

<p><br /></p>

<p>관광공사에서 제공하는 광안리 사진인데요, 확대해서 살펴보면 디테일한 광안리의 모습을 볼 수 있습니다.</p>

<p>이 사진에 모델이 추천하는 해시태그 20개는 다음과 같습니다.</p>

<blockquote>
  <p>#여행 #여행스타그램 #일상 #여행에미치다 #또가고싶다 #추억팔이 #여행사진 #국내여행 #떠나요 #휴가 #맞팔 #여행중 #소통 #가족여행 #여행추억 #가족스타그램 #여행그램 #travel #좋아요 #감성여행</p>
</blockquote>

<p>실제 사람이 쓸 것같은 해시태그를 잘 추천한 것으로 볼 수 있습니다.</p>

<p>이런 방식으로 관광공사에서 제공한 데이터에 모두 해시태그를 추출하는 작업을 수행합니다.</p>

<p><br /></p>

<h1 id="맞춤형-여행지-추천">맞춤형 여행지 추천</h1>

<p>그렇다면 여행지에서 추출한 해시태그를 기반으로 어떻게 사용자의 성향을 파악할 것인지가 관건이 됩니다.</p>

<p>이때 저희팀은 총 3번의 시행착오를 거쳤습니다.</p>

<p>우선 클러스터링을 통해 유사한 해시태그를 가지는 여행지를 추천하기로 하였습니다.</p>

<p>해시태그의 중요도를 증명하는 논문도 많이 있기 때문에, 사용자가 말하고자 하는 내용을 해시태그가 함축하여 담고 있을 것으로 판단하였습니다.</p>

<p><br /></p>

<h2 id="클러스터링">클러스터링</h2>

<p>클러스터링에는 여러 종류가 있는데, 우선적으로 저희가 시도한 것은 K-means, k-medoids 클러스터링이었습니다.</p>

<p>하지만 Elbow 방식으로 적절한 k 값을 살펴보았을 때, 눈에뛰게 꺾이는 부분을 찾을 수 없었습니다.</p>

<p><br /></p>

<p><img src="https://user-images.githubusercontent.com/48629275/153020755-33424e39-c0ec-4b76-8df5-56b827758fff.png" alt="kmeans" />
<img src="https://user-images.githubusercontent.com/48629275/153020758-105935a6-af6d-4709-8bdf-5198e4ac1d14.png" alt="kmedoids" /></p>

<p><br /></p>

<p>그래서 k-means의 실루엣 계수를 살펴보았는데 최대 0.05를 넘지 않는 모습으로 데이터를 분류하기 어렵다고 판단했습니다.</p>

<p><br /></p>

<p><img src="https://user-images.githubusercontent.com/48629275/153020746-453c0722-7196-440d-9283-4bdddbe87d5c.png" alt="실루엣 계수" /></p>

<p><br /></p>

<p>그렇다면 bottom-up 방식으로 비슷한 것을 찾는 DBSCAN을 시도했습니다.</p>

<p>하지만 추출한 20개의 해시태그 구분을 제대로 수행하지 못하였습니다.</p>

<p>DBSCAN은 입력 데이터의 차원이 큰 경우엔 사용하기 부적절하다고 합니다.</p>

<p>데이터 차원을 줄이고자 <strong>PCA</strong> 를 통해 차원압축을 시도했지만 큰 효과를 내지 못하는 상황이 발생헀습니다.</p>

<p>모델이 예측한 해시태그가 전체적으로 비슷한 내용을 가지고 있어 겹치는게 많다고 판단하여, 다른 방법을 시도했습니다.</p>

<p><br /></p>

<h2 id="우선순위">우선순위</h2>

<p><br /></p>

<p>다음으로 고려한 추천 방식은 해시태그가 추천된 <strong>우선순위</strong>를 고려하는 것입니다.</p>

<p>모델은 해당 게시글에 해당하는 전체 해시태그 확률을 softmax로 출력하고, 이 중에서 top_k (20개) 만 추출하여 해시태그가 달리게 됩니다.</p>

<p>가장 먼저 추천된 해시태그는 해당 게시글에 가장 적합하다는 뜻이기 때문에, 위치와 해시태그를 동시에 고려는 score를 계산해보았습니다.</p>

<p><br /></p>

<blockquote>
  <p>[예시]<br />
사용자 선택 이미지의 해시태그 - [여행, 일상, 여행스타그램, 추억팔이, 감성여행, …]<br />
비교 대상 이미지의 해시태그 - [여행일기, 강아지, 여행스타그램, 여행그램, 일상, …]<br />
2개의 해시태그 (‘일상’, ‘여행스타그램’) 만 겹치는 상황</p>
</blockquote>

<p><br /></p>

<p>예를 들어 다음과 같은 상황이 있다고 가정했을 때, 사용자가 선택한 이미지와 비교 대상 이미지의 유사도는 이렇게 계산됩니다.</p>

<ol>
  <li>[여행일기, 강아지, 여행스타그램, 여행그램, 일상, …] 중 일치하는 단어가 있는가?
    <ul>
      <li>Yes</li>
    </ul>
  </li>
  <li>일치하는 단어의 인덱스는 몇인가?
    <ul>
      <li>(1,4), (2,2)</li>
    </ul>
  </li>
</ol>

<p>총 20개의 해시태그가 있기 때문에 첫번째 해시태그가 일치할 경우는 20의 score를 얻게 됩니다.</p>

<p>이때 사용자가 선택한 이미지의 해시태그의 인덱스를 가중치로 곱하여 전체 누적시켜줍니다.</p>

<p>(19 * 16) + (18 * 18) = 628의 score를 가지게 됩니다.</p>

<p>겹치는 해시태그가 없으면 0이 됩니다.</p>

<p><br /></p>

<p>수식으로 표현하면 다음과 같습니다.</p>

\[score(a,b) = \Sigma (a_i * b_j)\]

\[a : 사용자가 \ 선택한 \ 이미지 \ 해시태그 \\ b : 비교 \ 대상 \ 이미지 \ 해시태그 \\ a_i : a \ 에서 \ 일치하는 \ 해시태그 \ 인덱스 \\ b_j : b \ 에서 \ 일치하는 \ 해스태그 \ 인덱스\]

<p><br /></p>

<p>사용자가 선택한 이미지가 누적될 수록 score도 계속 누적이 됩니다.</p>

<p>하지만 실제 추천을 해보니 바다를 중점적으로 골랐음에도 불구하고 절을 추천한다거나, 도서관을 추천하는 등 관계성을 찾기 힘든 여행지를 추천해줘서 다른 방법이 필요하다고 생각했습니다.</p>

<p><br /></p>

<h2 id="content-based-filltering">Content-based Filltering</h2>

<p><br /></p>

<p>해시태그의 우선순위가 크게 중요하지 않는다면 이미지가 가지고 있는 태그만 비교해서 유사한 항목을 추천하는 방식을 사용해보았습니다.</p>

<p><br /></p>

<ul>
  <li>유사도 측정 방식 : Cosine similarity</li>
</ul>

<p><br /></p>

<p>마찬가지로 사용자의 클릭이 다음 예측에도 영향을 미쳐야하기 때문에 유사도 역시 누적시켰습니다.</p>

<p>모델이 추천한 여행지 목록을 간단하게 보여드리겠습니다.</p>

<p><br /></p>

<p><img src="https://user-images.githubusercontent.com/48629275/153153757-c9a142a5-930a-4bbe-8532-e68b9956be7d.JPG" alt="추천결과1" />
<img src="https://user-images.githubusercontent.com/48629275/153153764-935f1b9b-7b42-431e-8f8c-24b770247b10.JPG" alt="추천결과2" />
<img src="https://user-images.githubusercontent.com/48629275/153153765-762aa824-ef5c-42d8-b236-d19a70d10295.JPG" alt="추천결과3" /></p>

<p><br /></p>

<p>1차 선택 이후 3차 선택까지는 나름 일관성이 있게 물놀이와 관련된 여행지를 추천해주었습니다.</p>

<p>하지만 최종 여행지 추천에 있어 삐끗하는 모습을 보이고 있습니다.</p>

<p>제한된 데이터가 문제인지 아니면 해시태그가 가지는 한계점인지, 모델이 제대로된 해시태그를 추천하지 못하였는지, 이 사진만 엉뚱하게 추천을 했는지 등 추측되는 부분들은 많았지만 정확한 문제점을 정의할 수 없었습니다.</p>

<p><br /></p>

<h1 id="평가">평가</h1>

<p>추천한 여행지에 대한 정답여부를 알 수 없기 때문에 일반적인 성능평가 방식은 적용하기 어려웠습니다.</p>

<p>그래서 저희는 무작위 사용자 50명을 대상으로 서비스 이용 만족도 조사를 실시하였습니다.</p>

<p>전체 사용자의 70% 가 여행지 추천 결과에 대한 만족스럽다는 평가를 해주었습니다.</p>

<p>아직 서비스가 완전한 상태가 아니기 때문에 AB 테스트를 진행하기엔 어려움이 있고, 대체로 사람들이 후한 점수를 주었을 것이라는 점도 배제할 수 없기 때문에 향후 발전방향에 대해서는 지속적인 논의가 필요할 것으로 생각됩니다.</p>

<p>또한 관광공사에서 제공하는 사진이 사용자의 관심을 끌 만큼 매력적이지 않다고 생각했습니다.</p>

<p>아무리 좋은 관광지라도 더 예쁘고 실제로 sns에 업로드 할 만큼의 퀄리티가 좋은 사진을 사용했다면 전체적으로 서비스의 만족도가 높아졌을 것이라는 아쉬움이 남습니다.</p>]]></content><author><name>조민규</name></author><category term="recommend system" /><category term="여행지 추천" /><category term="개인화 시스템" /><category term="AMNN" /><category term="추천 알고리즘" /><summary type="html"><![CDATA[]]></summary></entry></feed>